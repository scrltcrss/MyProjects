{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>Implementation of a Basic Object Detection using YOLOv8</h1>\n",
    "        <p>This project implements a basic object detection using the YOLOv8 model. YOLO (You Only Look Once) is a popular object detection algorithm that provides real-time object detection.</p>\n",
    "        <p>The YOLOv8 model used in this project is trained to detect various objects in images, and the implementation allows users to select an image and classify objects present in it.</p>\n",
    "        <p>The classifier utilizes the YOLOv8 model's predictions to identify and label objects in the selected image, providing users with insights into the contents of the image.</p>\n",
    "        <p>This implementation offers a simple and intuitive way to perform object classification tasks using YOLOv8, making it accessible to developers and enthusiasts interested in computer vision applications.</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Image Divider -->\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1358/1*YQWYPi4uoT8RcG6BPbUoVw.png\"  width=\"100%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49.7M/49.7M [00:01<00:00, 37.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\dog.110.jpg: 320x416 2 dogs, 103.7ms\n",
      "Speed: 1.0ms preprocess, 103.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\dog.104.jpg: 320x416 1 dog, 88.7ms\n",
      "Speed: 1.0ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\cat.116.jpg: 320x416 1 cat, 1 bed, 88.8ms\n",
      "Speed: 1.0ms preprocess, 88.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\rider-109.jpg: 416x416 2 persons, 1 horse, 119.6ms\n",
      "Speed: 2.0ms preprocess, 119.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\Zunge_raus.JPG: 416x320 1 person, 1 cat, 92.7ms\n",
      "Speed: 1.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 320)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\dog.110.jpg: 320x416 2 dogs, 89.7ms\n",
      "Speed: 1.0ms preprocess, 89.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\cat.116.jpg: 320x416 1 cat, 1 bed, 94.7ms\n",
      "Speed: 1.0ms preprocess, 94.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\cat.11.jpg: 416x416 1 bench, 1 cat, 1 dining table, 109.9ms\n",
      "Speed: 1.0ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "image 1/1 C:\\Users\\Daniil Bokhan\\Downloads\\yolov8_image_cl\\images\\rider-103.jpg: 416x288 5 persons, 1 horse, 102.7ms\n",
      "Speed: 0.0ms preprocess, 102.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 288)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk  # Import the tkinter module for creating GUI\n",
    "from tkinter import filedialog  # Import the filedialog module for opening file dialogs\n",
    "from PIL import Image, ImageTk  # Import Image and ImageTk modules from PIL for image handling\n",
    "from ultralytics import YOLO  # Import the YOLO class from ultralytics for object detection\n",
    "import cv2  # Import the OpenCV library for image processing\n",
    "\n",
    "\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(\"yolov8n.pt\")  # Initialize YOLO model with yolov8n.pt weights\n",
    "\n",
    "def clear_frame(frame):\n",
    "    \"\"\"Function to clear all widgets from a frame.\"\"\"\n",
    "    for widget in frame.winfo_children():\n",
    "        widget.destroy()  # Destroy all widgets in the frame\n",
    "\n",
    "def detect_objects(image_path, frame2):\n",
    "    \"\"\"Function to detect objects in the selected image and display the results.\"\"\"\n",
    "    # Use the YOLO model to detect objects in the image\n",
    "    result_predict = model.predict(source=image_path, imgsz=(416))\n",
    "\n",
    "    # Plot the detection results\n",
    "    plot = result_predict[0].plot()  # Plot the detected objects\n",
    "    plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)  # Convert plot to RGB format\n",
    "    display_image = Image.fromarray(plot)  # Convert the plot to an Image object\n",
    "    display_image = display_image.resize((416, 416))  # Resize the image\n",
    "    photo = ImageTk.PhotoImage(display_image)  # Convert the Image object to a PhotoImage\n",
    "\n",
    "    # Clear the frame\n",
    "    clear_frame(frame2)\n",
    "\n",
    "    # Display the detected image\n",
    "    label = tk.Label(frame2, image=photo, bd=2, relief=\"solid\")  # Create a label to display the image\n",
    "    label.image = photo  # Keep a reference to the image to prevent garbage collection\n",
    "    label.pack(pady=10)  # Pack the label into the frame\n",
    "\n",
    "    # Text label for the predictions\n",
    "    label_text2 = tk.Label(frame2, text=\"Predictions\", font=(\"Helvetica\", 14, \"bold\"), fg=\"white\", bg=\"#333333\")\n",
    "    label_text2.pack()  # Pack the text label into the frame\n",
    "\n",
    "def select_image(root, frame1, frame2):\n",
    "    \"\"\"Function to open a file dialog, select an image, and display it.\"\"\"\n",
    "    # Open a file dialog to select an image\n",
    "    image_path = filedialog.askopenfilename(title=\"Select Image\", filetypes=[(\"Image Files\", \"*.jpg;*.png;*.jpeg\")])\n",
    "\n",
    "    if image_path:\n",
    "        # Display the selected image\n",
    "        img = Image.open(image_path)  # Open the image file\n",
    "        img = img.resize((416, 416))  # Resize the image to 416x416 pixels\n",
    "        photo = ImageTk.PhotoImage(img)  # Convert the image to a PhotoImage\n",
    "\n",
    "        # Clear the frame\n",
    "        clear_frame(frame1)\n",
    "\n",
    "        # Display the loaded image\n",
    "        label = tk.Label(frame1, image=photo, bd=2, relief=\"solid\")  # Create a label to display the image\n",
    "        label.image = photo  # Keep a reference to the image to prevent garbage collection\n",
    "        label.pack(pady=10)  # Pack the label into the frame\n",
    "\n",
    "        # Text label for the loaded image\n",
    "        label_text1 = tk.Label(frame1, text=\"Loaded Image\", font=(\"Helvetica\", 14, \"bold\"), fg=\"white\", bg=\"#333333\")\n",
    "        label_text1.pack()  # Pack the text label into the frame\n",
    "\n",
    "        # Detect objects in the image\n",
    "        detect_objects(image_path, frame2)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to create the GUI.\"\"\"\n",
    "    root = tk.Tk()  # Create the main window\n",
    "    root.title(\"Object Detector\")  # Set the title of the window\n",
    "    root.geometry(\"1200x800\")  # Set the initial size of the window\n",
    "    root.configure(bg=\"#2c2c2c\")  # Set the background color of the window\n",
    "\n",
    "    # Create frames for images with rounded corners\n",
    "    frame1 = tk.Frame(root, bg=\"#333333\", bd=2, relief=\"ridge\")  # Create a frame for the left image\n",
    "    frame1.place(relx=0.1, rely=0.1, relwidth=0.35, relheight=0.75)  # Place the frame on the left side of the window\n",
    "\n",
    "    frame2 = tk.Frame(root, bg=\"#333333\", bd=2, relief=\"ridge\")  # Create a frame for the right image\n",
    "    frame2.place(relx=0.55, rely=0.1, relwidth=0.35, relheight=0.75)  # Place the frame on the right side of the window\n",
    "\n",
    "    # Create a button to select an image\n",
    "    select_button = tk.Button(root, text=\"Select Image\", command=lambda: select_image(root, frame1, frame2),\n",
    "                              font=(\"Helvetica\", 14, \"bold\"), bg=\"#4CAF50\", fg=\"white\", activebackground=\"#45a049\",\n",
    "                              bd=0, relief=\"flat\")\n",
    "    select_button.place(relx=0.45, rely=0.02, relwidth=0.1, relheight=0.05)  # Place the button at the top center of the window\n",
    "\n",
    "    root.mainloop()  # Start the main event loop\n",
    "\n",
    "main()  # Run \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>Сonclusion</h1>\n",
    "        <p>This project implements a simple GUI interface for image detection using the YOLOv8 model. Users can load an image file, detect objects in it, and view the detection results.</p>\n",
    "        <h2>Technologies Used:</h2>\n",
    "        <ul>\n",
    "            <li>Python</li>\n",
    "            <li>OpenCV: OpenCV (Open Source Computer Vision Library) provided essential functionality for video processing. It enabled tasks such as reading video files, processing individual frames, and writing the segmented video output.</li>\n",
    "            <li>Ultralytics YOLO: The YOLOv8 model</li>\n",
    "            <li>Tkinter: Tkinter, the standard GUI toolkit for Python</li>\n",
    "            <li>PIL: Python Imaging Library, used for image handling in the GUI</li>\n",
    "        </ul>\n",
    "            <h2>Sources</h2>\n",
    "            <ul>\n",
    "            <li>Email: daniilbokhan.q@gmail.com </li>\n",
    "            <li>Kaggle: https://www.kaggle.com/daniilbokhan </li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
