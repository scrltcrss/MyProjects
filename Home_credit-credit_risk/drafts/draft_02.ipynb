{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import optuna \n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # implement here all desired dtypes for tables\n",
    "    # the following is just an example\n",
    "    for col in df.columns:\n",
    "        # last letter of column name will help you determine the type\n",
    "        if col[-1] in (\"P\", \"A\"):\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:  \n",
    "        if df[col].dtype.name in ['object', 'string']:\n",
    "            df[col] = df[col].astype(\"string\").astype('category')\n",
    "            current_categories = df[col].cat.categories\n",
    "            new_categories = current_categories.to_list() + [\"Unknown\"]\n",
    "            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n",
    "            df[col] = df[col].astype(new_dtype)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_basetable = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\train\\\\train_base.csv\")\n",
    "train_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\train\\\\train_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\train\\\\train_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "train_static_cb = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\train\\\\train_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "train_person_1 = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\train\\\\train_person_1.csv\").pipe(set_table_dtypes) \n",
    "train_credit_bureau_b_2 = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\train\\\\train_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_basetable = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_base.csv\")\n",
    "test_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_static_0_2.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "test_static_cb = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "test_person_1 = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_person_1.csv\").pipe(set_table_dtypes) \n",
    "test_credit_bureau_b_2 = pl.read_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\csv_files\\\\test\\\\test_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A']\n",
      "['description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"
     ]
    }
   ],
   "source": [
    "# We need to use aggregation functions in tables with depth > 1, so tables that contain num_group1 column or \n",
    "# also num_group2 column.\n",
    "train_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "# Here num_group1=0 has special meaning, it is the person who applied for the loan.\n",
    "train_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "# Here we have num_goup1 and num_group2, so we need to aggregate again.\n",
    "train_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "# We will process in this examples only A-type and M-type columns, so we need to select them.\n",
    "selected_static_cols = []\n",
    "for col in train_static.columns:\n",
    "    if col[-1] in (\"A\", \"M\"):\n",
    "        selected_static_cols.append(col)\n",
    "print(selected_static_cols)\n",
    "\n",
    "selected_static_cb_cols = []\n",
    "for col in train_static_cb.columns:\n",
    "    if col[-1] in (\"A\", \"M\"):\n",
    "        selected_static_cb_cols.append(col)\n",
    "print(selected_static_cb_cols)\n",
    "\n",
    "# Join all tables together.\n",
    "data = train_basetable.join(\n",
    "    train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "test_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "test_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "data_submission = test_basetable.join(\n",
    "    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"
     ]
    }
   ],
   "source": [
    "case_ids = data[\"case_id\"].unique().shuffle(seed=1)\n",
    "case_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\n",
    "case_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n",
    "\n",
    "cols_pred = []\n",
    "for col in data.columns:\n",
    "    if col[-1].isupper() and col[:-1].islower():\n",
    "        cols_pred.append(col)\n",
    "\n",
    "print(cols_pred)\n",
    "\n",
    "def from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n",
    "    filtered_data = data.filter(pl.col(\"case_id\").is_in(case_ids))\n",
    "    return (\n",
    "        filtered_data[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n",
    "        filtered_data[cols_pred].to_pandas(),\n",
    "        filtered_data[\"target\"].to_pandas()\n",
    "    )\n",
    "\n",
    "base_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\n",
    "base_val, X_val, y_val = from_polars_to_pandas(case_ids_valid)\n",
    "base_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n",
    "\n",
    "for df in [X_train, X_val, X_test]:\n",
    "    df = convert_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (915995, 48)\n",
      "Valid: (305332, 48)\n",
      "Test: (305332, 48)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Valid: {X_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-01 04:05:06,710] A new study created in memory with name: no-name-921cc4d5-5a36-40b5-b2ab-14b2696a3f8f\n",
      "[I 2024-03-01 04:05:22,890] Trial 0 finished with value: 0.9690697339289691 and parameters: {'learning_rate': 0.0249816047538945, 'n_estimators': 591, 'lambda_l1': 0.012319939418114049, 'lambda_l2': 0.05190609389379257, 'max_depth': 6, 'colsample_bytree': 0.3935967122017216, 'subsample': 0.5290418060840998, 'min_child_samples': 45, 'num_leaves': 64}. Best is trial 0 with value: 0.9690697339289691.\n",
      "[I 2024-03-01 04:05:34,627] Trial 1 finished with value: 0.9690730090524413 and parameters: {'learning_rate': 0.03832290311184182, 'n_estimators': 404, 'lambda_l1': 0.014699098521619942, 'lambda_l2': 0.06827098485602953, 'max_depth': 7, 'colsample_bytree': 0.4090949803242604, 'subsample': 0.5917022549267169, 'min_child_samples': 22, 'num_leaves': 57}. Best is trial 1 with value: 0.9690730090524413.\n",
      "[I 2024-03-01 04:05:47,531] Trial 2 finished with value: 0.9690599085585526 and parameters: {'learning_rate': 0.02727780074568463, 'n_estimators': 458, 'lambda_l1': 0.011118528947223795, 'lambda_l2': 0.019764570245642932, 'max_depth': 7, 'colsample_bytree': 0.5198171059762151, 'subsample': 0.728034992108518, 'min_child_samples': 42, 'num_leaves': 28}. Best is trial 1 with value: 0.9690730090524413.\n",
      "[I 2024-03-01 04:06:01,256] Trial 3 finished with value: 0.969066458805497 and parameters: {'learning_rate': 0.030569377536544463, 'n_estimators': 519, 'lambda_l1': 0.005464504127199977, 'lambda_l2': 0.05252813963310069, 'max_depth': 6, 'colsample_bytree': 0.3390309557911677, 'subsample': 0.9744427686266666, 'min_child_samples': 49, 'num_leaves': 83}. Best is trial 1 with value: 0.9690730090524413.\n",
      "[I 2024-03-01 04:06:11,861] Trial 4 finished with value: 0.9690730090524413 and parameters: {'learning_rate': 0.022184550766934825, 'n_estimators': 419, 'lambda_l1': 0.011842330265121569, 'lambda_l2': 0.04081067456177209, 'max_depth': 6, 'colsample_bytree': 0.5971061460667622, 'subsample': 0.5171942605576092, 'min_child_samples': 47, 'num_leaves': 33}. Best is trial 1 with value: 0.9690730090524413.\n",
      "[I 2024-03-01 04:06:21,444] Trial 5 finished with value: 0.9690795592993856 and parameters: {'learning_rate': 0.03650089137415928, 'n_estimators': 462, 'lambda_l1': 0.010200680211778107, 'lambda_l2': 0.04826971955402958, 'max_depth': 6, 'colsample_bytree': 0.8817507766587351, 'subsample': 0.8875664116805573, 'min_child_samples': 48, 'num_leaves': 91}. Best is trial 5 with value: 0.9690795592993856.\n",
      "[I 2024-03-01 04:06:36,414] Trial 6 finished with value: 0.9690795592993856 and parameters: {'learning_rate': 0.03391599915244341, 'n_estimators': 585, 'lambda_l1': 0.005884925020519195, 'lambda_l2': 0.023718800369340168, 'max_depth': 5, 'colsample_bytree': 0.49519819845795865, 'subsample': 0.6943386448447411, 'min_child_samples': 21, 'num_leaves': 85}. Best is trial 5 with value: 0.9690795592993856.\n",
      "[I 2024-03-01 04:06:49,061] Trial 7 finished with value: 0.9690762841759134 and parameters: {'learning_rate': 0.024270133067743574, 'n_estimators': 456, 'lambda_l1': 0.010426960831582484, 'lambda_l2': 0.019864695748233387, 'max_depth': 13, 'colsample_bytree': 0.3447303862078625, 'subsample': 0.9934434683002586, 'min_child_samples': 41, 'num_leaves': 28}. Best is trial 5 with value: 0.9690795592993856.\n",
      "[I 2024-03-01 04:07:08,187] Trial 8 finished with value: 0.9690730090524413 and parameters: {'learning_rate': 0.010220884684944096, 'n_estimators': 563, 'lambda_l1': 0.012068573438476171, 'lambda_l2': 0.061030501762869116, 'max_depth': 12, 'colsample_bytree': 0.3444267910404542, 'subsample': 0.6792328642721364, 'min_child_samples': 14, 'num_leaves': 88}. Best is trial 5 with value: 0.9690795592993856.\n",
      "[I 2024-03-01 04:07:18,754] Trial 9 finished with value: 0.9690861095463299 and parameters: {'learning_rate': 0.03493192507310232, 'n_estimators': 466, 'lambda_l1': 0.0056355835028602365, 'lambda_l2': 0.031768762520096354, 'max_depth': 8, 'colsample_bytree': 0.7377637070028384, 'subsample': 0.8187787356776066, 'min_child_samples': 46, 'num_leaves': 52}. Best is trial 9 with value: 0.9690861095463299.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'learning_rate': 0.03493192507310232, 'n_estimators': 466, 'lambda_l1': 0.0056355835028602365, 'lambda_l2': 0.031768762520096354, 'max_depth': 8, 'colsample_bytree': 0.7377637070028384, 'subsample': 0.8187787356776066, 'min_child_samples': 46, 'num_leaves': 52}\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_valid = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n",
    "\n",
    "\n",
    "#The tuning process has been commented out due to its time-consuming nature.\n",
    "\n",
    "# Define the objective function for Optuna optimization\n",
    "def objective(trial, X_train, X_val, y_train, y_val):\n",
    "    #Define parameters to be optimized for the LGBMClassifier\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",#gbdt\n",
    "        \"random_state\": 42,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 600),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.005, 0.015),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 0.08),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 14),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.9),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 100),\n",
    "    }\n",
    "\n",
    "\n",
    "    lgbm_classifier = LGBMClassifier(**param)\n",
    "    lgbm_classifier.fit(X_train, y_train)\n",
    "    score = lgbm_classifier.score(X_val, y_val)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# Set up the sampler for Optuna optimization\n",
    "sampler = optuna.samplers.TPESampler(seed=42)  # Using Tree-structured Parzen Estimator sampler for optimization\n",
    "\n",
    "# Create a study object for Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "\n",
    "# Run the optimization process\n",
    "study.optimize(lambda trial: objective(trial, X_train, X_val, y_train, y_val), n_trials=10)\n",
    "\n",
    "# Get the best parameters after optimization\n",
    "best_params = study.best_params\n",
    "\n",
    "print('='*50)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0056355835028602365, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0056355835028602365\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.031768762520096354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031768762520096354\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0056355835028602365, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0056355835028602365\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.031768762520096354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031768762520096354\n",
      "[LightGBM] [Info] Number of positive: 28872, number of negative: 887123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8980\n",
      "[LightGBM] [Info] Number of data points in the train set: 915995, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031520 -> initscore=-3.425111\n",
      "[LightGBM] [Info] Start training from score -3.425111\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.7377637070028384,\n",
       "               lambda_l1=0.0056355835028602365, lambda_l2=0.031768762520096354,\n",
       "               learning_rate=0.03493192507310232, max_depth=8, metric=&#x27;auc&#x27;,\n",
       "               min_child_samples=46, n_estimators=466, num_leaves=52,\n",
       "               objective=&#x27;binary&#x27;, subsample=0.8187787356776066)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.7377637070028384,\n",
       "               lambda_l1=0.0056355835028602365, lambda_l2=0.031768762520096354,\n",
       "               learning_rate=0.03493192507310232, max_depth=8, metric=&#x27;auc&#x27;,\n",
       "               min_child_samples=46, n_estimators=466, num_leaves=52,\n",
       "               objective=&#x27;binary&#x27;, subsample=0.8187787356776066)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7377637070028384,\n",
       "               lambda_l1=0.0056355835028602365, lambda_l2=0.031768762520096354,\n",
       "               learning_rate=0.03493192507310232, max_depth=8, metric='auc',\n",
       "               min_child_samples=46, n_estimators=466, num_leaves=52,\n",
       "               objective='binary', subsample=0.8187787356776066)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_lgbm = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    'learning_rate': 0.03493192507310232, 'n_estimators': 466, 'lambda_l1': 0.0056355835028602365, 'lambda_l2': 0.031768762520096354, 'max_depth': 8, 'colsample_bytree': 0.7377637070028384, 'subsample': 0.8187787356776066, 'min_child_samples': 46, 'num_leaves': 52}\n",
    "\n",
    "\n",
    "\n",
    "lgbm_classifier = LGBMClassifier(**best_params_lgbm)\n",
    "lgbm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0056355835028602365, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0056355835028602365\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.031768762520096354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031768762520096354\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0056355835028602365, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0056355835028602365\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.031768762520096354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031768762520096354\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0056355835028602365, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0056355835028602365\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.031768762520096354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031768762520096354\n",
      "The AUC score on the train set is: 0.5031164889686818\n",
      "The AUC score on the valid set is: 0.501068117285037\n",
      "The AUC score on the test set is: 0.5012524252323455\n"
     ]
    }
   ],
   "source": [
    "for base, X in [(base_train, X_train), (base_val, X_val), (base_test, X_test)]:\n",
    "    y_pred = lgbm_classifier.predict(X)\n",
    "    base[\"score\"] = y_pred\n",
    "\n",
    "print(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], base_train[\"score\"])}') \n",
    "print(f'The AUC score on the valid set is: {roc_auc_score(base_val[\"target\"], base_val[\"score\"])}') \n",
    "print(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stability score on the train set is: 0.0031918685290863234\n",
      "The stability score on the valid set is: -0.0006921044334633223\n",
      "The stability score on the test set is: -0.0008989638505342598\n"
     ]
    }
   ],
   "source": [
    "def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n",
    "    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n",
    "        .sort_values(\"WEEK_NUM\")\\\n",
    "        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n",
    "        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n",
    "    \n",
    "    x = np.arange(len(gini_in_time))\n",
    "    y = gini_in_time\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_hat = a*x + b\n",
    "    residuals = y - y_hat\n",
    "    res_std = np.std(residuals)\n",
    "    avg_gini = np.mean(gini_in_time)\n",
    "    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n",
    "\n",
    "stability_score_train = gini_stability(base_train)\n",
    "stability_score_valid = gini_stability(base_val)\n",
    "stability_score_test = gini_stability(base_test)\n",
    "\n",
    "print(f'The stability score on the train set is: {stability_score_train}') \n",
    "print(f'The stability score on the valid set is: {stability_score_valid}') \n",
    "print(f'The stability score on the test set is: {stability_score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0056355835028602365, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0056355835028602365\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.031768762520096354, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.031768762520096354\n"
     ]
    }
   ],
   "source": [
    "X_submission = data_submission[cols_pred].to_pandas()\n",
    "X_submission = convert_strings(X_submission)\n",
    "categorical_cols = X_train.select_dtypes(include=['category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_categories = set(X_train[col].cat.categories)\n",
    "    submission_categories = set(X_submission[col].cat.categories)\n",
    "    new_categories = submission_categories - train_categories\n",
    "    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n",
    "    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n",
    "    X_train[col] = X_train[col].astype(new_dtype)\n",
    "    X_submission[col] = X_submission[col].astype(new_dtype)\n",
    "\n",
    "y_submission_pred = lgbm_classifier.predict(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n",
    "    \"score\": y_submission_pred\n",
    "}).set_index('case_id')\n",
    "submission.to_csv(\"C:\\\\Users\\\\Daniil Bokhan\\\\Desktop\\\\csv\\\\bankcredit-riskCOMPETITION\\\\bankcredit-riskCOMPETITIONsub\\\\sub2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
